#!/usr/bin/perl

#
# defaults
#

use Parse::AccessLogEntry;
use strict;
use Getopt::GUI::Long;
use XML::Simple;
use Data::Dumper;
use File::Temp qw(tempfile);
use IO::File;

#
# Option parsing
#
my %opts = (d => '/var/log/httpd');

Getopt::GUI::Long::Configure(qw(display_help no_ignore_case
				capture_output no_gui allow_zero));
GetOptions(\%opts,
	   ["s|site=s",          "Only look for data for website name STRING"],
	   ["d|log-directory=s", "Directory containing the log files"],
	   ["S|log-suffix=s",    "Adds a file suffix to log files searched for"],
	   ["p|path=s",          "Adds search path components for include files"],
	   ["GUI:separator",     "Debugging"],
	   ["debug",             "Debugging output"],
	   ["D|dump-config",     "Dump config being used for each site"],
	   ["GUI:otherargs_text", "XML_Config_File"],
	  ) || exit 1;

#
# Configuration File
#
# read in the .xml config file with special <include> processing
#
my $xmlfile = $ARGV[0] || $ENV{'HOME'} . "/.httpsum.xml";

my ($tmpxmlh, $tmpxmlfile) = tempfile();

DEBUG("creating temporary XML file from input files");
read_xml_file($tmpxmlh, $xmlfile);
$tmpxmlh->close();

DEBUG("reading XML file");
my $config = XMLin($tmpxmlfile,
		   ForceArray => [qw(ignorefile agent site
				     transformreferer transformfile
				     ignorereferer ignoreuseragent)]);
unlink($tmpxmlfile);

my $parser = Parse::AccessLogEntry::new();
my %results;

# figure out what sites to look for
my @sites = split(/,\s*/,$opts{'s'});
@sites = keys(%{$config->{'sites'}{'site'}}) if ($#sites == -1);

site:
foreach my $site (@sites) {
    my $sitedata = get_config($config, $site);

    print "\n----- $site -----\n\n";

    print Dumper($sitedata) if ($opts{'D'});

    # open each needed log file
    my $files = $sitedata->{'file'};
    $files = $sitedata->{'directory'} . "/" . $files if ($files !~ /\//);

    # output data goes in the results hash
    my %results;

    # a list of the bots that searched the site
    my %bots;

    # a count of the number of bots
    my $robots;

    foreach my $file (glob($files)) {
	DEBUG("processing $file");
	if (! -f $file) {
	    print STDERR "** failed to open file $file\n";
	    next site;
	}

	open(I, $file);
      line:
	while (<I>) {

	    # process the line and skip if it's a HEAD request
	    my $parts = $parser->parse($_);
	    next if ($parts->{'rtype'} eq 'HEAD');

	    foreach my $map (keys(%{$sitedata->{'agent'}})) {
		if ($parts->{'agent'} =~ /$map/) {
		    $parts->{'agent'} = $sitedata->{'agent'}{$map}{'content'};
		    if ($sitedata->{'agent'}{$map}{'bot'}) {
			$bots{$parts->{'agent'}}++;
			next line;
		    }
		    last;
		}
	    }

	    # ignore things that look at the robots.txt file
	    # XXX: should be configurable; skip "U" agent
	    if ($parts->{'file'} =~ /robots.txt/) {
		$results{$parts->{'file'}}{'robot'}++;
		$results{$parts->{'file'}}{'count'}++;
# XXX
# 		push @useragentignores, $parts->{'agent'}
# 		  if (!exists($bots{$parts->{'agent'}}));

		print "** possible bot:  $parts->{'agent'}\n";

		$bots{$parts->{'agent'}}++;
		$robots++;
		next;
	    }

	    # process teh list of files to ignore
	    foreach my $fileig (@{$sitedata->{'ignorefile'}}) {
		next line if ($parts->{'file'} =~ /$fileig/);
	    }

	    # ignore things based on referals
	    foreach my $refer (@{$sitedata->{'ignorereferer'}}) {
		next line if ($parts->{'refer'} =~ /$refer/);
	    }

	    foreach my $host (@{$sitedata->{'ignorehost'}}) {
		next line if ($parts->{'host'} =~ /$host/);
	    }

	    foreach my $useragent (@{$sitedata->{'ignoreuseragent'}}) {
		next line if ($parts->{'agent'} eq $useragent);
	    }

	    foreach my $transform (keys(%{$sitedata->{'transformreferer'}})) {
		$parts->{'refer'} =~ s/$transform/eval "\"$sitedata->{'transformreferer'}{$transform}{'content'}\""/e;
	    }

	    foreach my $transform (keys(%{$sitedata->{'transformfile'}})) {
		$parts->{'file'} =~ s/$transform/eval "\"$sitedata->{'transformfile'}{$transform}{'content'}\""/e;
	    }

	    # finally classify the results
	    $results{$parts->{'file'}}{$parts->{'refer'}}++;
	    $results{$parts->{'file'}}{'count'}++;
	}
    }

    print "Bot hits:\n";
    foreach my $bot (keys(%bots)) {
	$bot =~ s/[^;]+; *//;
	$bot =~ s/;.*//;
	printf("%6d %s\n", $bots{$bot}, $bot);
    }

    print "\nHits:\n";
    foreach my $file (sort { $results{$a}{'count'} <=> $results{$b}{'count'} } keys(%results)) {
	printf "%6d %-70.70s\n", $results{$file}{'count'}, $file;
	foreach my $referer (sort { $results{$file}{$a} <=> $results{$file}{$b} } keys(%{$results{$file}})) {
	    next if ($referer eq 'count');
	    next if ($referer eq '-');
	    printf "  %6d %-70.70s\n",$results{$file}{$referer}, $referer;
	}
    }
}


sub get_config {
    my ($xmldata, $site) = @_;

    my $sitedata = $xmldata->{'sites'}{'site'}{$site};

    # ARRAYs
    # copy each value from a set of config tokens into the array
    foreach my $key (qw(ignorefile)) {
	foreach my $value (@{$xmldata->{'global'}{$key}}) {
	    push @{$sitedata->{$key}}, $value;
	}
    }

    # SCALARs
    # copy each value from a set of config tokens into the array
    foreach my $key (qw(directory file)) {
	$sitedata->{$key} = $xmldata->{'global'}{$key}
	  if (!exists($sitedata->{$key}));
	$sitedata->{$key} =~ s/\%{site}/$site/g;
    }

    # NAME = VALUE
    # copy each value and each name into the config array
    foreach my $key (qw(agent transformreferer)) {
	foreach my $name (keys(%{$xmldata->{'global'}{$key}})) {
	    if (!exists($sitedata->{$key}{$name})) {
		$sitedata->{$key}{$name} = $xmldata->{'global'}{$key}{$name};
	    }
	}
    }

    # supply a few defaults
    $sitedata->{'file'} = "$site.log" if (!exists($sitedata->{'file'}));
    $sitedata->{'directory'} = $opts{'d'} if (!exists($sitedata->{'directory'}));

    $sitedata->{'file'} .= $opts{'S'} if (defined($opts{'S'}));

    return $sitedata;
}

sub read_xml_file {
    my ($tmpxmlh, $file) = @_;
    my $fileh = new IO::File;

    # locate the file
    if (! -f $file) {
	my @searchpath = (".", split(",", $opts{'p'}),
			  $ENV{'HOME'} . "/.httpsum",
			  "/usr/share/httpsum/include-modules",
			  "/usr/local/share/httpsum/include-modules");
	my $found = 0;
	foreach my $path (@searchpath) {
	    if (-f "$path/$file") {
		$file = "$path/$file";
		$found = 1;
		last;
	    }
	}
	if (!$found) {
	    print STDERR "*** failed to locate include file '$file'; continuing anyway\n";
	    return;
	}
    }

    DEBUG("  reading $file");
    $fileh->open("< $file");
    while (<$fileh>) {
	if (/<include>\s*(.*)<\/include>/) {
	    my $file = $1;
	    chomp($file);
	    read_xml_file($tmpxmlh, $file);
	} elsif (/<include\s+src=\"(.*)\"\s*\/>/){
	    read_xml_file($tmpxmlh, $1);
	}
	print $tmpxmlh $_;
    }
    $fileh->close();
}

sub DEBUG {
    if ($opts{'debug'}) {
	print @_,"\n";
    }
}


=pod

=head1 NAME

httpsum - Summarize apache log files

=head1 SYNOPSIS

httpsum -d /path/to/logfiles [XML_CONFIG_FILE]

=head1 OPTIONS

=over

=item -d PATH

Specifies the directory to look in for logfiles.

=item -S suffix

Specifies the filename suffix to require.  Useful for looking for log
entries for a specific date, if the logs are rotated daily.  EG:

  httpsum -S .`date -d yesterday +%Y-%m-%d`

=head1 XML_CONFIG_FILE

The XML_CONFIG_FILE is a configuration file that dictates how
reporting should be done and for what sites.  If no file is specified
B<httpsum> will look in I<~/.httpsum.xml>.

=back

=cut

